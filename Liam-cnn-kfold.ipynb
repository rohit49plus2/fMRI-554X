{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "import god_config as config\n",
    "dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17250, 45, 29, 22)\n",
      "(17250,)\n",
      "14750\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "# roi = 'VC'\n",
    "# X = np.load(dir_path+'/data/Subject1_'+roi+'_fmri.npy')\n",
    "# datatype=np.load(dir_path+'/data/Subject1_datatype.npy')\n",
    "X = np.load(dir_path+'/padded_data/VC.npy')\n",
    "datatype = np.load(dir_path+'/padded_data/datatype.npy')\n",
    "y = np.zeros((len(datatype),))\n",
    "y[np.where(datatype == 3)[0]] = 1\n",
    "\n",
    "print (X.shape)\n",
    "print (y.shape)\n",
    "print (len(y[y == 0]))\n",
    "print (len(y[y == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_into_dataloader(X,y, batch_size):\n",
    "    newX = torch.Tensor(X).unsqueeze_(1)\n",
    "    newy = torch.LongTensor(y)\n",
    "    dataset = data_utils.TensorDataset(newX,newy)\n",
    "    dataloader = data_utils.DataLoader(dataset,\n",
    "                                      batch_size = batch_size,\n",
    "                                      num_workers = 0,\n",
    "                                      shuffle = True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the convolutional neural network model\n",
    "#Note: Each fmri scan is of size 45 x 29 x 22\n",
    "class fmriNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fmriNet, self).__init__()\n",
    "        #conv1, conv2, and conv3 maintain input dimensions\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        #conv4 changes data to object of size 20 x 13 x 9\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, (7,5,4), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv5, conv6, and conv7 maintain dimensions 20 x 13 x 9\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv8 changes data to object of size 7 x 5 x 4\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, (8,5,3), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv9, conv10, and conv11 maintain dimensions 7 x 5 x 4\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        \n",
    "        #Flatten to vector of length 32 x 7 x 5 x 4 = 4480\n",
    "        #Fully connected layer from 4480 to 100\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(4480, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #Fully connected layer from 100 to 10\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1000,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(100,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #Fully connected layer from 10 to 2, being the two outputs\n",
    "        self.fcout = nn.Linear(10,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.conv9(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.conv11(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fcout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to test the model\n",
    "def test(model, data_loader):\n",
    "    print (\"Testing Accuracy...\")\n",
    "    total_items = 0\n",
    "    total_steps = len(data_loader)\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(data_loader):\n",
    "            #move data to gpu\n",
    "            fmris = sample[0].to(device)\n",
    "            labels = sample[1].to(device)\n",
    "            total_items += len(labels)\n",
    "            \n",
    "            #feed data forward\n",
    "            outputs = model(fmris)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += torch.sum(predicted == labels).item()\n",
    "            #print (\"Step [{}/{}]\".format(i+1, total_steps, end = \"\\r\"))\n",
    "                   \n",
    "    acc = correct/total_items\n",
    "    print (\"Accuracy: {:.2f}% [{}/{}]\".format(acc*100, correct,total_items))\n",
    "    return acc\n",
    "    \n",
    "#Function to perform k-fold cross validation on the model\n",
    "def train(model, train_loader, num_epochs, criterion, optimizer, losses = []):\n",
    "    model.train()\n",
    "    losses = losses\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    for i in range(num_epochs):\n",
    "        for j, sample in enumerate(train_loader):\n",
    "            #move data to gpu\n",
    "            fmris = sample[0].to(device)\n",
    "            labels = sample[1].to(device)\n",
    "\n",
    "            #feed data forward\n",
    "            outputs = model(fmris)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss)\n",
    "\n",
    "            #backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print (\"Training Epoch: [{}/{}]\\tStep: [{}/{}]\\tLoss:{:.10f}\".format(i+1,num_epochs,j+1,steps_per_epoch, loss), end = \"\\r\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "Augmenting Data...\n",
      "Training Epoch: [2/4]\tStep: [294/369]\tLoss:0.0624318048\r"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 4\n",
    "betas = (0.9,0.999) #defaults (known to be applicable in most situations according to creator's publication)\n",
    "l2 = 0.01\n",
    "#optimizer and loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#device to train on\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"Running on:\",device)\n",
    "\n",
    "scores=[]\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=2)\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    #Put data in dataloaders\n",
    "    print (\"Augmenting Data...\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    over = SMOTE(random_state=2)\n",
    "    under = RandomUnderSampler(random_state=2)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train=X_train.reshape(X_train.shape[0],-1)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    X_train = X_train.reshape(-1,X.shape[1], X.shape[2], X.shape[3])\n",
    "    X_test = X_test.reshape(-1,X.shape[1], X.shape[2], X.shape[3])\n",
    "    train_loader = make_into_dataloader(X_train, y_train,batch_size)\n",
    "    test_loader = make_into_dataloader(X_test,y_test,batch_size)\n",
    "    \n",
    "    #Create model\n",
    "    model = fmriNet()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = betas, weight_decay = l2)\n",
    "    \n",
    "    #Training\n",
    "    losses = train(model, train_loader, num_epochs, criterion, optimizer, losses = [])\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "    #Testing\n",
    "    acc = test(model, test_loader)\n",
    "    scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897101449275363 0.007843512537817302\n"
     ]
    }
   ],
   "source": [
    "print (np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4769492\n"
     ]
    }
   ],
   "source": [
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "print (model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For original WeightedRandomSampler implementation\n",
    "#Load the fMRI data that we processed to be 3 dimensional rectangles by \n",
    "#filling in zeros around the data into X\n",
    "X=np.load(dir_path+'/data/'+'Subject1'+'_'+'VC'+'_'+'fmri'+'.npy')\n",
    "X=X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "X = torch.Tensor(X).unsqueeze_(1) #need to add a x1 dimension so pytorch doesn't complain when training\n",
    "\n",
    "#Load the labels: \n",
    "# - 0 corresponds to seen data\n",
    "# - 1 corresponds to imagined data\n",
    "datatype=np.load(dir_path+'/data/'+'Subject1'+'_'+'datatype'+'.npy')\n",
    "y = np.zeros((len(datatype),))\n",
    "y[np.where(datatype == 3)[0]] = 1\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "#Split the data into 80% training, 20% testing\n",
    "dataset = data_utils.TensorDataset(X, y)\n",
    "train_set_size = int(0.8 * len(y))\n",
    "train_set, test_set = data_utils.random_split(dataset, [train_set_size, len(y) - train_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmriNet is better, don't need this one\n",
    "\n",
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        #45 x 29 x 20\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, (11,6,5)),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        #35x24x16\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, (11,6,5)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        #25x19x12\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(16,32,(11,6,5)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        #15x14x8\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(32,64,(6,5,3)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        #10x10x6\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(64,128,(4,4,3)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU())\n",
    "        #7x7x4\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv3d(128,256, (4,4,2)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU())\n",
    "        #4x4x3 x 256 = 12288\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(12288, 1000),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1000,100),\n",
    "            nn.ReLU())\n",
    "        self.fcout = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fcout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "absavgdata = np.average(X.reshape(X.shape[0],-1),axis = 1)\n",
    "plt.scatter(y,absavgdata)\n",
    "plt.xlabel('Seen Vs. Imagined')\n",
    "plt.ylabel('Average For Each Sample')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
