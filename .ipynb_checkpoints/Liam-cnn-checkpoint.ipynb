{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "dir_path = \"/home/liam/Documents/Classes/CPSC554X/project/fMRI-554X\" #can change this to be more general later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the fMRI data that we processed to be 3 dimensional rectangles by \n",
    "#filling in zeros around the data into X\n",
    "X=np.load(dir_path+'/data/'+'Subject1'+'_'+'VC'+'_'+'fmri'+'.npy')\n",
    "X=X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "X = torch.Tensor(X).unsqueeze_(1) #need to add a x1 dimension so pytorch doesn't complain when training\n",
    "\n",
    "#Load the labels: \n",
    "# - 0 corresponds to seen data\n",
    "# - 1 corresponds to imagined data\n",
    "datatype=np.load(dir_path+'/data/'+'Subject1'+'_'+'datatype'+'.npy')\n",
    "y = np.zeros((len(datatype),))\n",
    "y[np.where(datatype == 3)[0]] = 1\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "#Split the data into 80% training, 20% testing\n",
    "dataset = data_utils.TensorDataset(X, y)\n",
    "train_set_size = int(0.8 * len(y))\n",
    "train_set, test_set = data_utils.random_split(dataset, [train_set_size, len(y) - train_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#Note: The classes are unbalance, we will use pytorch's WeightedRandomSampler function to try to account for this\n",
    "print (len(y[y==0]))\n",
    "print (len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Weighted Random Sampler\n",
    "seen_prob = 1/len(y[y==0])\n",
    "imag_prob = 1/len(y[y==1])\n",
    "batch_size = 60\n",
    "sampler = data_utils.sampler.WeightedRandomSampler([seen_prob, imag_prob], len(train_set), replacement = True)\n",
    "\n",
    "#Create the pytorch Dataloader objects\n",
    "train_loader = data_utils.DataLoader(train_set,\n",
    "                                     batch_size = batch_size,\n",
    "                                     num_workers = 6,\n",
    "                                     sampler = sampler)\n",
    "\n",
    "test_loader = data_utils.DataLoader(test_set,\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False,\n",
    "                                    num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print (len(train_loader))\n",
    "print (len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sample in enumerate(train_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the convolutional neural network model\n",
    "#Note: Each fmri scan is of size 45 x 29 x 20 \n",
    "class fmriNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fmriNet, self).__init__()\n",
    "        #conv1, conv2, and conv3 maintain input dimensions\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        #conv4 changes data to object of size 20 x 13 x 9\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, (7,5,4), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv5, conv6, and conv7 maintain dimensions 20 x 13 x 9\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv8 changes data to object of size 7 x 5 x 4\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, (8,5,3), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv9, conv10, and conv11 maintain dimensions 7 x 5 x 4\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #Flatten to vector of length 32 x 7 x 5 x 4 = 4480\n",
    "        #Fully connected layer from 4480 to 100\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(4480, 100),\n",
    "            nn.ReLU())\n",
    "        #Fully connected layer from 100 to 10\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(100,10),\n",
    "            nn.ReLU())\n",
    "        #Fully connected layer from 10 to 2, being the two outputs\n",
    "        self.fcout = nn.Linear(10,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.conv9(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.conv11(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fcout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize model and move to gpu if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = fmriNet()\n",
    "model.to(device)\n",
    "\n",
    "#hyperparameters other than batch size above\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "betas = (0.9,0.999) #defaults (known to be applicable in most situations according to creator's publication)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = betas, weight_decay = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10]\tStep: [11/46]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d71716c94da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#feed data forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liam/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-bd4175a7d87d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liam/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liam/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liam/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liam/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    478\u001b[0m                             self.dilation, self.groups)\n\u001b[1;32m    479\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 480\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "losses = []\n",
    "steps_per_epoch = int(len(train_set)/batch_size)\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    for j, sample in enumerate(train_loader):\n",
    "        #move data to gpu\n",
    "        fmris = sample[0].to(device)\n",
    "        labels = sample[1].to(device)\n",
    "        \n",
    "        #feed data forward\n",
    "        outputs = model(fmris)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print (\"Epoch: [{}/{}]\\tStep: [{}/{}]\\tLoss:{:.10f}\".format(i+1,num_epochs,j,steps_per_epoch, loss), end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f77205effd0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507246376811595\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "model.eval() #turns off moving average in batch normalization\n",
    "total_items = len(test_set)\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        #move data to gpu\n",
    "        fmris = sample[0].to(device)\n",
    "        labels = sample[1].to(device)\n",
    "        \n",
    "        #feed data forward\n",
    "        outputs = model(fmris)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += torch.sum(predicted == labels).item()\n",
    "        print (\"Step [{}/{}]\".format(i+1, len(test_loader)), end = \"\\r\")\n",
    "        \n",
    "print (correct/total_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Could create custom dataset class instead of using TensorDataset\n",
    "# class fMRIDataset(data_utils.Dataset):\n",
    "#     def __init__(self, X, y):\n",
    "#         self.fmri = X\n",
    "#         self.label = y\n",
    "#         self.len = len(y)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "    \n",
    "#     def __getitem__(self, i):\n",
    "#         return {'fmri':self.fmri[i],'label':self.label[i]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
