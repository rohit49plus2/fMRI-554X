{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "dir_path = \"/home/liam/Documents/Classes/CPSC554X/project/fMRI-554X\" #can change this to be more general later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the fMRI data that we processed to be 3 dimensional rectangles by \n",
    "#filling in zeros around the data into X\n",
    "X=np.load(dir_path+'/data/'+'Subject1'+'_'+'VC'+'_'+'fmri'+'.npy')\n",
    "X=X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "X = torch.Tensor(X).unsqueeze_(1) #need to add a x1 dimension so pytorch doesn't complain when training\n",
    "\n",
    "#Load the labels: \n",
    "# - 0 corresponds to seen data\n",
    "# - 1 corresponds to imagined data\n",
    "datatype=np.load(dir_path+'/data/'+'Subject1'+'_'+'datatype'+'.npy')\n",
    "y = np.zeros((len(datatype),))\n",
    "y[np.where(datatype == 3)[0]] = 1\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "#Split the data into 80% training, 20% testing\n",
    "dataset = data_utils.TensorDataset(X, y)\n",
    "train_set_size = int(0.8 * len(y))\n",
    "train_set, test_set = data_utils.random_split(dataset, [train_set_size, len(y) - train_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#Note: The classes are unbalance, we will use pytorch's WeightedRandomSampler function to try to account for this\n",
    "print (len(y[y==0]))\n",
    "print (len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Weighted Random Sampler\n",
    "seen_prob = 1/len(y[y==0])\n",
    "imag_prob = 1/len(y[y==1])\n",
    "batch_size = 60\n",
    "sampler = data_utils.sampler.WeightedRandomSampler([seen_prob, imag_prob], len(train_set), replacement = False)\n",
    "\n",
    "#Create the pytorch Dataloader objects\n",
    "train_loader = data_utils.DataLoader(train_set,\n",
    "                                     batch_size = batch_size,\n",
    "                                     num_workers = 0,\n",
    "                                     sampler = sampler)\n",
    "\n",
    "test_loader = data_utils.DataLoader(test_set,\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False,\n",
    "                                    num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        #45 x 29 x 20\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, (11,6,5)),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        #35x24x16\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, (11,6,5)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        #25x19x12\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(16,32,(11,6,5)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        #15x14x8\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(32,64,(6,5,3)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        #10x10x6\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(64,128,(4,4,3)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU())\n",
    "        #7x7x4\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv3d(128,256, (4,4,2)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU())\n",
    "        #4x4x3 x 256 = 12288\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(12288, 1000),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1000,100),\n",
    "            nn.ReLU())\n",
    "        self.fcout = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fcout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the convolutional neural network model\n",
    "#Note: Each fmri scan is of size 45 x 29 x 20 \n",
    "class fmriNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fmriNet, self).__init__()\n",
    "        #conv1, conv2, and conv3 maintain input dimensions\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(8, 8, 3, padding = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU())\n",
    "        #conv4 changes data to object of size 20 x 13 x 9\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, (7,5,4), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv5, conv6, and conv7 maintain dimensions 20 x 13 x 9\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding = 1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv8 changes data to object of size 7 x 5 x 4\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, (8,5,3), stride = (2,2,2)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #conv9, conv10, and conv11 maintain dimensions 7 x 5 x 4\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU())\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, padding = 1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        \n",
    "        #Flatten to vector of length 32 x 7 x 5 x 4 = 4480\n",
    "        #Fully connected layer from 4480 to 100\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(4480, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #Fully connected layer from 100 to 10\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1000,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(100,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #Fully connected layer from 10 to 2, being the two outputs\n",
    "        self.fcout = nn.Linear(10,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.conv9(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.conv11(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fcout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#initialize model and move to gpu if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)\n",
    "#model = fmriNet()\n",
    "model = testNet()\n",
    "model.to(device)\n",
    "\n",
    "#hyperparameters other than batch size above\n",
    "num_epochs = 1\n",
    "learning_rate = 0.0001\n",
    "betas = (0.9,0.999) #defaults (known to be applicable in most situations according to creator's publication)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = betas, weight_decay = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1]\tStep: [46/46]\tLoss:0.0000233970\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training the model\n",
    "losses = []\n",
    "steps_per_epoch = int(len(train_set)/batch_size)\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    for j, sample in enumerate(train_loader):\n",
    "        #move data to gpu\n",
    "        fmris = sample[0].to(device)\n",
    "        labels = sample[1].to(device)\n",
    "        \n",
    "        #feed data forward\n",
    "        outputs = model(fmris)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (\"Epoch: [{}/{}]\\tStep: [{}/{}]\\tLoss:{:.10f}\".format(i+1,num_epochs,j+1,steps_per_epoch, loss), end = \"\\r\")\n",
    "        if (j+1 == steps_per_epoch):\n",
    "            plt.plot(losses)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.76811594202898\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "model.eval() #turns off moving average in batch normalization\n",
    "total_items = len(test_set)\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        #move data to gpu\n",
    "        fmris = sample[0].to(device)\n",
    "        labels = sample[1].to(device)\n",
    "        \n",
    "        #feed data forward\n",
    "        outputs = model(fmris)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += torch.sum(predicted == labels).item()\n",
    "        print (\"Step [{}/{}]\".format(i+1, len(test_loader)), end = \"\\r\")\n",
    "        \n",
    "print (correct/total_items*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14230766\n"
     ]
    }
   ],
   "source": [
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "print (model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
